{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_scover_bs\",\n  \"trial_id\": \"cde25e48\",\n  \"config\": {\n    \"batch_size\": 256,\n    \"learning_rate\": 0.00010286595235614708,\n    \"sigma_motifs\": 0.0009021420210980302,\n    \"sigma_net\": 0.0003489185430153528\n  },\n  \"local_dir\": \"/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover\",\n  \"evaluated_params\": {\n    \"batch_size\": 256,\n    \"learning_rate\": 0.00010286595235614708,\n    \"sigma_motifs\": 0.0009021420210980302,\n    \"sigma_net\": 0.0003489185430153528\n  },\n  \"experiment_tag\": \"1_batch_size=256,learning_rate=0.00010287,sigma_motifs=0.00090214,sigma_net=0.00034892\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 3,\n  \"_last_result\": {\n    \"loss\": 2.0902047157287598,\n    \"time_this_iter_s\": 3.373565673828125,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 10,\n    \"trial_id\": \"cde25e48\",\n    \"experiment_id\": \"aae4b8293a8545c99fcd29a20a65e6cf\",\n    \"date\": \"2022-04-28_23-38-22\",\n    \"timestamp\": 1651185502,\n    \"time_total_s\": 37.477957010269165,\n    \"pid\": 25282,\n    \"hostname\": \"farm5-gpu0102\",\n    \"node_ip\": \"10.160.0.18\",\n    \"config\": {\n      \"batch_size\": 256,\n      \"learning_rate\": 0.00010286595235614708,\n      \"sigma_motifs\": 0.0009021420210980302,\n      \"sigma_net\": 0.0003489185430153528\n    },\n    \"time_since_restore\": 37.477957010269165,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 10,\n    \"warmup_time\": 0.0038285255432128906,\n    \"experiment_tag\": \"1_batch_size=256,learning_rate=0.00010287,sigma_motifs=0.00090214,sigma_net=0.00034892\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1651185502.2373528,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 5.660562038421631,\n      \"min\": 2.0902047157287598,\n      \"avg\": 2.6884911298751835,\n      \"last\": 2.0902047157287598,\n      \"last-5-avg\": 2.119701290130615,\n      \"last-10-avg\": 2.688491129875183\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8.291214227676392,\n      \"min\": 3.166714906692505,\n      \"avg\": 3.7477957010269165,\n      \"last\": 3.373565673828125,\n      \"last-5-avg\": 3.247761678695679,\n      \"last-10-avg\": 3.7477957010269165\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.1,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 37.477957010269165,\n      \"min\": 8.291214227676392,\n      \"avg\": 22.827895021438597,\n      \"last\": 37.477957010269165,\n      \"last-5-avg\": 30.904592752456665,\n      \"last-10-avg\": 22.8278950214386\n    },\n    \"time_since_restore\": {\n      \"max\": 37.477957010269165,\n      \"min\": 8.291214227676392,\n      \"avg\": 22.827895021438597,\n      \"last\": 37.477957010269165,\n      \"last-5-avg\": 30.904592752456665,\n      \"last-10-avg\": 22.8278950214386\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0038285255432128906,\n      \"min\": 0.0038285255432128906,\n      \"avg\": 0.0038285255432128906,\n      \"last\": 0.0038285255432128906,\n      \"last-5-avg\": 0.0038285255432128906,\n      \"last-10-avg\": 0.0038285255432128906\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740013659e000000047400112cb00000000474000f33e40000000474000d49d60000000474000b8bd40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474016a46a6000000047400e91cc000000004740037b646000000047400196ab800000004740015dde000000004740013659e000000047400112cb00000000474000f33e40000000474000d49d60000000474000b8bd40000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740097f95c0000000474009556ea000000047400a9f6ea000000047400977916000000047400afd1000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020951a0800000047400962c3a000000047400a8f2da00000004740098a354000000047400a1938200000004740097f95c0000000474009556ea000000047400a9f6ea000000047400977916000000047400afd1000000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740386d2b9000000047403b97d96400000047403eebc7380000004740410d5cb2000000474042bd2db2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020951a08000000474026edcaf000000047402d919658000000474031fa11d40000004740353d38d80000004740386d2b9000000047403b97d96400000047403eebc7380000004740410d5cb2000000474042bd2db2000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740386d2b9000000047403b97d96400000047403eebc7380000004740410d5cb2000000474042bd2db2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020951a08000000474026edcaf000000047402d919658000000474031fa11d40000004740353d38d80000004740386d2b9000000047403b97d96400000047403eebc7380000004740410d5cb2000000474042bd2db2000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000473f6f5d0000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1651185457.4321473,\n  \"logdir\": \"/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover/train_scover_bs_cde25e48_1_batch_size=256,learning_rate=0.00010287,sigma_motifs=0.00090214,sigma_net=0.00034892_2022-04-28_23-37-37\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_scover_bs\",\n  \"trial_id\": \"d25bc8e2\",\n  \"config\": {\n    \"batch_size\": 128,\n    \"learning_rate\": 0.0021387171433009575,\n    \"sigma_motifs\": 7.18092243918592e-05,\n    \"sigma_net\": 0.0014882358308796581\n  },\n  \"local_dir\": \"/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover\",\n  \"evaluated_params\": {\n    \"batch_size\": 128,\n    \"learning_rate\": 0.0021387171433009575,\n    \"sigma_motifs\": 7.18092243918592e-05,\n    \"sigma_net\": 0.0014882358308796581\n  },\n  \"experiment_tag\": \"2_batch_size=128,learning_rate=0.0021387,sigma_motifs=7.1809e-05,sigma_net=0.0014882\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 3,\n  \"_last_result\": {\n    \"loss\": 1.6809628009796143,\n    \"time_this_iter_s\": 2.3247246742248535,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 10,\n    \"trial_id\": \"d25bc8e2\",\n    \"experiment_id\": \"b7469f73d0ad43d58d62384da9b38b45\",\n    \"date\": \"2022-04-28_23-38-56\",\n    \"timestamp\": 1651185536,\n    \"time_total_s\": 27.59681534767151,\n    \"pid\": 28604,\n    \"hostname\": \"farm5-gpu0102\",\n    \"node_ip\": \"10.160.0.18\",\n    \"config\": {\n      \"batch_size\": 128,\n      \"learning_rate\": 0.0021387171433009575,\n      \"sigma_motifs\": 7.18092243918592e-05,\n      \"sigma_net\": 0.0014882358308796581\n    },\n    \"time_since_restore\": 27.59681534767151,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 10,\n    \"warmup_time\": 0.0033211708068847656,\n    \"experiment_tag\": \"2_batch_size=128,learning_rate=0.0021387,sigma_motifs=7.1809e-05,sigma_net=0.0014882\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1651185536.9181273,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 1.9772952795028687,\n      \"min\": 1.6602987051010132,\n      \"avg\": 1.7868488788604737,\n      \"last\": 1.6809628009796143,\n      \"last-5-avg\": 1.7082364320755006,\n      \"last-10-avg\": 1.7868488788604737\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6.951925277709961,\n      \"min\": 2.1964974403381348,\n      \"avg\": 2.759681534767151,\n      \"last\": 2.3247246742248535,\n      \"last-5-avg\": 2.3002925395965574,\n      \"last-10-avg\": 2.759681534767151\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.1,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 27.59681534767151,\n      \"min\": 6.951925277709961,\n      \"avg\": 17.26946015357971,\n      \"last\": 27.59681534767151,\n      \"last-5-avg\": 22.9811794757843,\n      \"last-10-avg\": 17.26946015357971\n    },\n    \"time_since_restore\": {\n      \"max\": 27.59681534767151,\n      \"min\": 6.951925277709961,\n      \"avg\": 17.26946015357971,\n      \"last\": 27.59681534767151,\n      \"last-5-avg\": 22.9811794757843,\n      \"last-10-avg\": 17.26946015357971\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0033211708068847656,\n      \"min\": 0.0033211708068847656,\n      \"avg\": 0.0033211708068847656,\n      \"last\": 0.0033211708068847656,\n      \"last-5-avg\": 0.0033211708068847656,\n      \"last-10-avg\": 0.0033211708068847656\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ffb1f6160000000473ffb1cde40000000473ffcf6a060000000473ffa909560000000473ffae53940000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fffa30060000000473ffed02380000000473ffddaa560000000473ffc8d2a80000000473ffc61b220000000473ffb1f6160000000473ffb1cde40000000473ffcf6a060000000473ffa909560000000473ffae53940000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400259e680000000474001dc82600000004740033b3120000000474001f85ba0000000474002990940000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401bcec58000000047400307462000000047400236c820000000474001926d400000004740025541c000000047400259e680000000474001dc82600000004740033b3120000000474001f85ba0000000474002990940000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403263a5d80000004740349f3624000000474037069c4800000047403945a7bc00000047403b98c8e4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401bcec580000000474022a9344800000047402736e65000000047402b9b81a000000047403018690800000047403263a5d80000004740349f3624000000474037069c4800000047403945a7bc00000047403b98c8e4000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403263a5d80000004740349f3624000000474037069c4800000047403945a7bc00000047403b98c8e4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401bcec580000000474022a9344800000047402736e65000000047402b9b81a000000047403018690800000047403263a5d80000004740349f3624000000474037069c4800000047403945a7bc00000047403b98c8e4000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000473f6b350000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1651185503.0052283,\n  \"logdir\": \"/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover/train_scover_bs_d25bc8e2_2_batch_size=128,learning_rate=0.0021387,sigma_motifs=7.1809e-05,sigma_net=0.0014882_2022-04-28_23-38-22\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005958b000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 1,
    "_metric": null,
    "_total_time": 65.07477235794067,
    "_iteration": 25,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1651185457.2535422,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-04-28_23-37-37",
    "checkpoint_file": "/lustre/scratch123/hgi/mdt2/teams/parts/jh47/tmp/scovernew/example_notebooks/Marrow_pool80_tune/Marrow_pool80_7_tune_scover/experiment_state-2022-04-28_23-37-37.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1651185457.2535422,
    "timestamp": 1651185529.9550357
  }
}