---
title: "How to prepare scanem input using a scRNA-seq dataset"
author: "Jacob Hepkema"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

All **scanem** needs as input are sequences and values. These sequences can be

* Promoter sequences
* Peak sequences

The values then represent transcriptional activity or accessibility across 
cell pools respectively. 

The way that **scanem** pools cells together is to, for a given pool size, 
sum the expression or accessibility values of random (mutually exclusive) 
groups of cells of that size, making sure to only pool cells together of 
the same cell type. 

That's why you need cell type annotation in addition to a counts matrix to 
be able to do the pooling. 

In this workflow, I'm starting from a `SingleCellExperiment` object containing scRNA-seq data (see 
[this page](https://bioconductor.org/packages/release/bioc/vignettes/SingleCellExperiment/inst/doc/intro.html) for useful information on what this is) - if you start from a counts 
matrix, follow the instructions on [this page](https://bioconductor.org/packages/release/bioc/vignettes/SingleCellExperiment/inst/doc/intro.html) to construct a `SingleCellExperiment` object. If you are
starting from a `Seurat` object, [their website](https://satijalab.org/seurat/v3.0/conversion_vignette.html) contains 
useful information on how to convert this to a `SingleCellExperiment` object. 

This workflow is the more detailed data generation file - if you are just 
interested in creating a dataset quickly, there's a script for this too. 
You can then start from a `SingleCellExperiment`
object with the cell type annotation stored in `colData(sce)$cell_type1` (where
`sce` is the `SingleCellExperiment` object) . See [this page](https://htmlpreview.github.io/?https://github.com/jacobhepkema/scanem/blob/master/guides/how_to_prepare_scanem_dataset_using_create_dataset.html) for more information 
on the 'quick version'. However, it's always good to pay attention if the steps
make sense - having a 'human in the loop' for dataset generation and model output 
analysis will often help. 

For creating a dataset using scATAC-seq data, see the other workflow in this repo. 

## Loading the required packages and helper functions

I'm using the following packages during this part of the workflow:

```{r load_r_packages, eval=TRUE, echo=TRUE, warning=FALSE}
suppressMessages(library(AnnotationHub))
suppressMessages(library(assertr))
suppressMessages(library(Biostrings))
suppressMessages(library(GenomicRanges))
suppressMessages(library(Matrix))
suppressMessages(library(SingleCellExperiment))
suppressMessages(library(scater))
suppressMessages(library(stringr))

options(stringsAsFactors = F)
```

See the end of this page for the full `sessionInfo()`. 

In addition, I get my helper functions (e.g. `pool_cells()`) from this file:

```{r sourcefile}
source("scanem_helper_functions.R")
```

**Important**: 
All of the required R scripts and fasta files are included in the `data_generation` folder of this repository. 


## Creating a dataset from a scRNA-seq dataset

Load your `SingleCellExperiment` object. In this case I'm using the bone marrow dataset from Tabula Muris:

```{r load_sce, eval=T, echo=T}
sce <- readRDS("TMFACS_Marrow.rds")
```

Make sure that the cell type information is stored in the `$cell_type1` column of `colData(sce)`. 
You can check this using:

```{r cell_type_info}
table(sce$cell_type1)
```

Also make sure that the cell type information does not contain any `NA`s.

```{r remove_na}
sce <- sce[,!is.na(sce$cell_type1)]
```

In addition, you could choose not to include cells that have an "unknown" cell type. 

## Determining optimal pool size

Pooling cells together for **scanem** is a tradeoff between getting rid of unpredictable zeroes in your count
matrix and keeping variability between cells and cell types. Generally, the method works reasonably well for 
datasets between 20% and 50% sparsity - aiming for a sparsity below 50% is usually a good idea. However, 
it is always good to try a couple of different settings because this is quite dependent on your dataset.

Also, it's sometimes not possible to reduce the sparsity up to that level - in that case, 
it's good to try a couple of different pool sizes to see what works best. 

One way to check how sparsity goes down for different pool sizes is to try it:
(the `pool_cells()` and `get_sce_sparsity()` functions are from `scanem_helper_functions.R`)

```{r determine_sparsity}
sparsities <- c()
for(pool_size in c(12,30,50,100,200)){
  sparsities <- c(sparsities, get_sce_sparsity(pool_cells(sce, pool_size=pool_size)))
}
plot(x=c(12,30,50,100,200), y=sparsities, 
     main="Sparsity for different pool sizes", 
     xlab="Pool size", ylab="Sparsity")
```

As you can see, for this particular dataset, there is not a lot of benefit of pooling beyond pool size 50.
Because genes with very low dropout will be filtered out, the dropout ratio will likely go down beyond this. 
Note that for pool sizes beyond a particular size, you lose cell types as they have less than pool_size cells.

In this case, I'll use `pool_size = 50`. I use the `pool_cells_follow_cells()` function to keep track of 
which cells end up in which pools. 

```{r gen_pooled_dataset}
pool_output <- pool_cells_follow_cells(sce, pool_size=50, keep_smaller_pools = F)
pooled_sce <- pool_output[[1]]
pooled_sce_cells_in_pools <- pool_output[[2]]
```

## Extracting sequences

For this particular dataset, I know that `mm10` was used, so I'll open the relevant sequences from the mm10 
genome with 500 bp upstream and 500 bp downstream of the TSS for each gene.
This file is included in the `data_generation` folder of this repository. 

```{r get_seqs}
seqs <- Biostrings::readDNAStringSet("./mm10_500up500down_promoters.fa.gz")

# Get genes and to-be-predicted data (log-normalized counts of sce)
genelist <- rownames(pooled_sce)
data <- logcounts(pooled_sce) 

# Figure out which genes are not included in the sequences list:
not_in_fasta <- genelist[!(genelist %in% names(seqs))]

length(not_in_fasta)
```

If this last number (`length(not_in_fasta)`) is very high, it's likely that you are using the wrong version 
of the genome. 
I've included other fasta files for these sequences in this repository; e.g. `hg38_500up500down_promoters.fa.gz`. 
It is also possible to extract your own sequences using `AnnotationHub` - I've created a guide at `how_to_extract_promoter_sequences.Rmd`.

Let's filter out cells/genes with too high dropout:

```{r filter_cells_genes}
genelist <- genelist[genelist %in% names(seqs)]

cell_dropouts <- colSums(data == 0) / dim(data)[1]
too_high_cell_dropouts <- cell_dropouts > 0.98
cat(sum(too_high_cell_dropouts))

data <- data[,!too_high_cell_dropouts]
pooled_sce <- pooled_sce[,!too_high_cell_dropouts]

gene_dropouts <- rowSums(data == 0) / dim(data)[2]
too_high_gene_dropouts <- genelist[gene_dropouts[genelist] > 0.98]
cat(length(too_high_gene_dropouts))

genelist <- genelist[!(gene_dropouts[genelist] > 0.98)]

cat("Genelist of", length(genelist), "genes\n")
cat("Cell/pool number:", ncol(data),"\n")
```

Now let's extract the sequences and to-be-predicted values:

```{r extract_all}
seqs <- base::tolower(as.character(seqs[genelist]))
ind <- assertr::col_concat(data[genelist,], sep=",")
```

Now all that's left is to write three tables:
 
1. The table containing the sequences and the to-be-predicted values
2. The table containing annotations for the different cell pools
3. The table containing information about which cell ended up in which pool

```{r write_dataset}
dataset <- data.frame(gene=genelist,
                      sequence=seqs,
                      ind=ind)

write.table(dataset, gzfile("TMFACS_Marrow_pool50.tsv.gz"), 
            sep="\t", row.names = F, col.names = T, quote = F)
write.table(colData(pooled_sce), "TMFACS_Marrow_pool50_colData.tsv", 
            sep="\t", row.names = T, col.names = T, quote = F)
write.table(pooled_sce_cells_in_pools, "TMFACS_Marrow_pool50_cells_in_pools.tsv", 
            sep="\t", row.names = T, col.names = T, quote = F)
```

You want to pass file 1) to the `--data` argument of scanem, and argument 2) to
`--celldata` of scanem. For more information on how to run **scanem**, see the main readme file 
in the root of this repository. 


## Used packages

```{r sessioninfo}
utils::sessionInfo()
```


