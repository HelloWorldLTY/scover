---
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

All **scover** needs as input are a set of sequences and a set of numeric values associated with each sequence (typically represented as a matrix). The sequences can be any type of nucleotides, e.g.

* Promoter sequences
* Peak sequences
* UTRs

The values represent transcriptional activity, accessibility, or some other property associated with each sequence. It is assumed that each cell has a value and that values can be averaged across a randomly selected pool of cells from the same cell type. **scover** utilizes the cell type annotation to pool cells from the same group by sampling without replacement. 

In this workflow, I am starting from a `SingleCellExperiment` object containing scATAC-seq data (see 
                                                                                                 [this page](https://bioconductor.org/packages/release/bioc/vignettes/SingleCellExperiment/inst/doc/intro.html) for useful information on what this is) - if you start from a counts matrix, follow the [instructions](https://bioconductor.org/packages/release/bioc/vignettes/SingleCellExperiment/inst/doc/intro.html) to construct a `SingleCellExperiment` object. If you are starting from a `Seurat` object, [their website](https://satijalab.org/seurat/v3.0/conversion_vignette.html) contains 
useful information on how to convert this to a `SingleCellExperiment` object. 

There is another [workflow for using scRNA-seq data](https://scover.readthedocs.io/en/latest/how_to_prepare_scover_input_using_scRNA_seq.html). 

## Loading the required packages and helper functions

I am using the following packages during this part of the workflow:
  
```{r load_r_packages, eval=TRUE, echo=TRUE, warning=FALSE}
suppressMessages(library(AnnotationHub))
suppressMessages(library(assertr))
suppressMessages(library(Biostrings))
suppressMessages(library(GenomicRanges))
suppressMessages(library(Matrix))
suppressMessages(library(SingleCellExperiment))
suppressMessages(library(scater))
suppressMessages(library(stringr))
options(stringsAsFactors = F)
```

See the end of this page for the full `sessionInfo()`. 

In addition, I get my helper functions (e.g. `pool_cells()`) from this file:
  
```{r sourcefile}
source("scover_helper_functions.R")
```

**Important**: 
All of the required R scripts and fasta files are included in the `resources` folder of this repository. 


## Creating a dataset from a scATAC-seq dataset

Load your `SingleCellExperiment` object. In this case I am using a SNARE-seq dataset with cells from the adult mouse cerebral cortex:
  
```{r load_sce, eval=T, echo=T}
sce <- readRDS(paste0(snare_dir, "GSE126074_AdBrainCortex_SNAREseq_sce.rds"))
```

I know that the cell type annotations are currently not in `colData(sce)$cell_type1`, 
but rather in `colData(sce)$Ident`, so I update the object:
  
```{r update_ann}
sce$cell_type1 <- sce$Ident
```

Also make sure that the cell type information does not contain any `NA`s.

```{r remove_na}
sce <- sce[,!is.na(sce$cell_type1)]
```

In addition, it is good practice to exclude cells that have an "unknown" cell type. 

In this case, I know that the dataset contains both genes and peak regions. This is something I do not want in this case, 
so I will identify where the genes end to select the peaks only. 

```{r peaks_only}
# Identify index of first row name starting with "chr"
print(which(str_detect(rownames(sce), "^chr"))[1])
# See if thats the right one
print(rownames(sce)[33161]) # first peak
print(rownames(sce)[33160]) # last gene
# Select peaks only
sce <- sce[-c(1:33160),]
# Check what this looks like
print(head(rownames(sce)))
```

## Determining optimal pool size

Pooling cells together for **scover** is a trade off between removing undesired zeroes in your count
matrix and retaining variability between cells and cell types. For the datasets that I have worked with so far, a pool size of 100 cells per pool works well, as it reduces the sparsity below 70%. However, I recommend that you try a couple of different settings since the number of remaining pools and the sparsity depends on your dataset. Sometimes it is impossible to reduce the sparsity below 70% - in that case, I recommend that you try a couple of different pool sizes to see what works best. 

One way to check how sparsity goes down for different pool sizes is to try it:
  (the `pool_cells()` and `get_sce_sparsity()` functions are from `scover_helper_functions.R`)

```{r determine_sparsity}
sparsities <- c()
for(pool_size in c(12,30,50,100,200)){
  sparsities <- c(sparsities, get_sce_sparsity(pool_cells(sce, pool_size=pool_size)))
}
plot(x=c(12,30,50,100,200), y=sparsities, 
     main="Sparsity for different pool sizes", 
     xlab="Pool size", ylab="Sparsity")
```

Note that for large pool sizes, you will lose cell types that have fewer than `pool_size` cells. 
In this case, I will use `pool_size = 100`. I use the `pool_cells_follow_cells()` function to keep track of 
which cells end up in which pools. 

```{r gen_pooled_dataset}
pool_output <- pool_cells_follow_cells(sce, pool_size=100, keep_smaller_pools = F)
pooled_sce <- pool_output[[1]]
pooled_sce_cells_in_pools <- pool_output[[2]]
```

## Adjust region sizes

This part of the workflow will only work if the rownames of the `SingleCellExperiment` object
represent the peak regions in the format: `chromosome_peakstart_peakend`, e.g.
`chr1_283990_284520`. In most peak regions, TFs occupy sequences around the middle of the peak. 
To decrease runtimes and increase signal/noise, I recommend taking the 
middle 250 bp for each peak region:
  
```{r take_middle}
peaknames <- rownames(pooled_sce)
peak_start <- as.numeric(str_remove(str_remove(peaknames, "^chr[a-zA-Z0-9]+_"), "_[0-9]+$"))
peak_end <- as.numeric(str_remove(peaknames, "^chr[a-zA-Z0-9]+_[0-9]+_"))
peak_chrom <- str_remove(peaknames, "_[0-9]+_[0-9]+$")
peak_middles <- round((peak_end+peak_start)/2)
peak_start <- peak_middles-125
peak_end <- peak_middles+124
# Create peak ranges
peak_ranges_df <- data.frame(seqnames=peak_chrom,
                             start=peak_start,
                             end=peak_end)
peak_ranges <- makeGRangesFromDataFrame(peak_ranges_df)
```

If the peak regions are represented using a different syntax (e.g. `chromosome:peakstart-peakend`) then
it is necessary to update the regular expressions found in the code block above
(For the example, with the `chromosome:peakstart-peakend` format, the updated first line then becomes
`peak_start <- as.numeric(str_remove(str_remove(peaknames, "^chr[a-zA-Z0-9]+:"), "-[0-9]+$"))`).

## Removing peaks that overlap promoter regions

For this particular dataset, I am interested in finding the regulatory elements in peaks from distal regulatory regions. I am going to filter out the peaks that overlap regions between -8 kb and +0.5 kb around the transcription start sites. Since I know that the `mm10` genome was used I use AnnotationHub to find the corresponding annotation, and I use it to generate promoter regions:
  
```{r get_prom_regions}
ah <- AnnotationHub()
# Let's find mm10 annotation
query(ah, c("GRCm38", "gtf"))
mm10_gtf <- ah[["AH69533"]]
# Get unique genes in annotation
genes <- mm10_gtf[mm10_gtf$type == "gene" & 
                    seqnames(mm10_gtf) %in% c(1:19, "X", "Y")]
genes <- genes[!duplicated(genes$gene_name),]
# This defines how many bp upstream and downstream of TSSs you want to extract
upstream = 8000
downstream = 500
# This returns a GRanges object:
promoter_ranges <- GenomicRanges::promoters(genes, 
                                            upstream = upstream, 
                                            downstream = downstream)
seqlevelsStyle(promoter_ranges) <- "UCSC"
```

I can identify peak regions that overlap these promoter ranges:
  
```{r find_overlaps_ranges}
ranges_promoter_overlap <- findOverlaps(peak_ranges, promoter_ranges, ignore.strand=F, minoverlap = 1)
ranges_overlapping_with_promoter <- unique(ranges_promoter_overlap@from)
ranges_that_overlap <- (1:length(peak_ranges) %in% ranges_overlapping_with_promoter)
```

Remove the ranges overlapping promoter ranges:
  
```{r remove_overlaps}
# Exclude peak ranges overlapping with promoter_ranges
peak_ranges <- peak_ranges[!ranges_that_overlap]
pooled_sce <- pooled_sce[!ranges_that_overlap,]
```

Now I will extract the sequences from the `mm10` genome using the peak ranges. 

```{r get_seqs}
# Find annotation
mm10 <- ah[["AH14005"]]
# Get sequences from genome
sequences <- Biostrings::getSeq(mm10, peak_ranges)
```

See if any sequences contain "N":
  
```{r check_n}
has_n <- str_detect(sequences, "n|N")
print(sum(has_n))
```

Remove those:
  
```{r remove_n}
sequences <- sequences[!has_n]
pooled_sce <- pooled_sce[!has_n,]
```

Filter out cells/peaks with too high dropout:
  
```{r filter_cells_genes}
data <- logcounts(pooled_sce)
cell_dropouts <- colSums(data == 0) / dim(data)[1]
too_high_cell_dropouts <- cell_dropouts > 0.98
cat(sum(too_high_cell_dropouts))
data <- data[,!too_high_cell_dropouts]
pooled_sce <- pooled_sce[,!too_high_cell_dropouts]
peak_dropouts <- rowSums(data == 0) / dim(data)[2]
too_high_peak_dropouts <- peak_dropouts > 0.98
cat(sum(too_high_peak_dropouts))
sequences <- sequences[!too_high_peak_dropouts]
data <- data[!too_high_peak_dropouts,]
cat("Peak list of", length(sequences), "peaks\n")
cat("Number of pools:", ncol(data),"\n")
```

Extract the sequences and the values to be used for the prediction task:
  
```{r extract_all}
seqs <- base::tolower(as.character(sequences))
ind <- assertr::col_concat(data, sep=",")
```

Now all that is left is to write three tables:
  
1. The table containing the sequences and the associated values
2. The table containing annotations for the different cell pools
3. The table containing information about which cell ended up in which pool

```{r write_dataset}
dataset <- data.frame(region=rownames(data),
                      sequence=seqs,
                      ind=ind)

# File 1
write.table(dataset, gzfile("SNARE_seq_Adult_pool100.tsv.gz"), 
            sep="\t", row.names = F, col.names = T, quote = F)

# File 2
write.table(colData(pooled_sce), "SNARE_seq_Adult_pool100_colData.tsv", 
            sep="\t", row.names = T, col.names = T, quote = F)

# File 3
write.table(pooled_sce_cells_in_pools, "SNARE_seq_Adult_pool100_cells_in_pools.tsv", 
            sep="\t", row.names = T, col.names = T, quote = F)
```

`File 1` becomes the input file for the `scover` argument `--data`, and 
`File 2` becomes the input file for the `scover` argument `--celldata`. 

The third file ensures that it is possible to reproduce the pooling.

## Used packages

```{r sessioninfo}
utils::sessionInfo()
```
